{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shinnew9/cse337-cse437RL/blob/main/lab10_half_cheetah_dynamics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "199af124",
      "metadata": {
        "id": "199af124"
      },
      "source": [
        "\n",
        "# HalfCheetah: Learn a Dynamics Model from Random Rollouts (Then Validate It)\n",
        "\n",
        "**Goal:** In this notebook you'll (1) collect random experience tuples \\((s_t, a_t, r_t, s_{t+1})\\) from `HalfCheetah-v4`, (2) train a neural network to predict **state deltas** \\(\\Delta s = s_{t+1}-s_t\\), and (3) **validate** the model with one-step and multi-step (open-loop) rollouts.\n",
        "\n",
        "This mirrors the first phase of model-based control (e.g., MPPI): learn a model offline, then use it for planning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b3392de",
      "metadata": {
        "id": "2b3392de"
      },
      "source": [
        "\n",
        "## 0. Requirements\n",
        "\n",
        "- Python 3.9+\n",
        "- PyTorch `>= 1.10`\n",
        "- Gymnasium `>= 0.29`\n",
        "- MuJoCo with `HalfCheetah-v4` (install `mujoco` and `gymnasium[mujoco]`)\n",
        "\n",
        "```bash\n",
        "pip install \"gymnasium[mujoco]\" mujoco torch matplotlib\n",
        "```\n",
        "\n",
        "**Try and understand what RunningNormalizer does.**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"gymnasium[mujoco]\" mujoco torch matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXuFecd_Ma1W",
        "outputId": "9a836ddb-2e21-4126-b782-5f20afb6e231"
      },
      "id": "FXuFecd_Ma1W",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mujoco\n",
            "  Downloading mujoco-3.3.7-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: gymnasium[mujoco] in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (0.0.4)\n",
            "Requirement already satisfied: imageio>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (2.37.0)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (25.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mujoco) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.12/dist-packages (from mujoco) (1.13.0)\n",
            "Collecting glfw (from mujoco)\n",
            "  Downloading glfw-2.10.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.12/dist-packages (from mujoco) (3.1.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Downloading mujoco-3.3.7-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading glfw-2.10.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl (243 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m243.5/243.5 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: glfw, mujoco\n",
            "Successfully installed glfw-2.10.0 mujoco-3.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c1213bd2",
      "metadata": {
        "id": "c1213bd2"
      },
      "outputs": [],
      "source": [
        "import os, math, random, time\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple\n",
        "import numpy as np\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import gymnasium as gym\n",
        "\n",
        "def to_t(x):\n",
        "    return th.as_tensor(x, dtype=th.float32)\n",
        "\n",
        "def fanin_init(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        bound = 1.0 / math.sqrt(m.weight.size(1))\n",
        "        nn.init.uniform_(m.weight, -bound, +bound)\n",
        "        nn.init.zeros_(m.bias)\n",
        "\n",
        "class RunningNormalizer:\n",
        "    \"\"\"Feature-wise running mean/std (Welford).\"\"\"\n",
        "    def __init__(self, dim, eps=1e-8):\n",
        "        self.dim = dim\n",
        "        self.count = 0\n",
        "        self.mean = np.zeros(dim, dtype=np.float64)\n",
        "        self.M2   = np.zeros(dim, dtype=np.float64)\n",
        "        self.eps  = eps\n",
        "\n",
        "    def update(self, x: np.ndarray):\n",
        "        x = np.asarray(x)\n",
        "        if x.ndim == 1: x = x[None, :]\n",
        "        for v in x:\n",
        "            self.count += 1\n",
        "            d = v - self.mean\n",
        "            self.mean += d / self.count\n",
        "            d2 = v - self.mean\n",
        "            self.M2 += d * d2\n",
        "\n",
        "    @property\n",
        "    def var(self):\n",
        "        if self.count < 2: return np.ones(self.dim, dtype=np.float64)\n",
        "        return self.M2 / (self.count - 1 + 1e-12)\n",
        "\n",
        "    @property\n",
        "    def std(self):\n",
        "        return np.sqrt(self.var + self.eps)\n",
        "\n",
        "    def normalize(self, x): return (x - self.mean) / self.std\n",
        "    def denormalize(self, x): return x * self.std + self.mean\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed); th.manual_seed(seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "304b5ce5",
      "metadata": {
        "id": "304b5ce5"
      },
      "source": [
        "\n",
        "## Initializing Environment and Figure Out Observation Structure\n",
        "\n",
        "`HalfCheetah-v4` exposes observations as `[qpos[1:], qvel[:]]`. The forward velocity is `qvel[0]`, which sits at index `len(qpos[1:])` inside the observation vector. We'll extract that index for later validation/plots. :::: This is important for planning, if we want to know what each state represents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5de69613",
      "metadata": {
        "id": "5de69613",
        "outputId": "4653dee6-f547-41b0-e70e-2878dd5c56ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py:512: DeprecationWarning: \u001b[33mWARN: The environment HalfCheetah-v4 is out of date. You should consider upgrading to version `v5`.\u001b[0m\n",
            "  logger.deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "obs_dim: 17 act_dim: 6 qvel_start: 8\n"
          ]
        }
      ],
      "source": [
        "set_seed(42)\n",
        "env = gym.make(\"HalfCheetah-v4\")\n",
        "obs_dim = env.observation_space.shape[0]\n",
        "act_dim = env.action_space.shape[0]\n",
        "act_low = env.action_space.low\n",
        "act_high = env.action_space.high\n",
        "\n",
        "# Find start index of qvel inside obs = [qpos[1:], qvel[:]]\n",
        "nq = env.unwrapped.model.nq\n",
        "qvel_start = int(nq - 1)\n",
        "print(\"obs_dim:\", obs_dim, \"act_dim:\", act_dim, \"qvel_start:\", qvel_start)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e071b0bb",
      "metadata": {
        "id": "e071b0bb"
      },
      "source": [
        "## ğŸ§© Task 1: Prepare the Replay Buffer\n",
        "**Goal:** Store transitions \\((s_t, a_t, s_{t+1})\\) and return training pairs \\((x, y) = (s_t, a_t, s_{t+1} - s_t)\\).\n",
        "\n",
        "**Instructions:**\n",
        "- Implement `add()` to record transitions.\n",
        "- Add a `sample()` method to randomly sample batch of certain size.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "08628879",
      "metadata": {
        "id": "08628879"
      },
      "outputs": [],
      "source": [
        "# Create the class and create a class object\n",
        "class Replay:\n",
        "    def __init__(self, obs_dim, act_dim, capacity=300000):\n",
        "        self.obs = np.zeros((capacity, obs_dim), dtype=np.float32)\n",
        "        self.act = np.zeros((capacity, act_dim), dtype=np.float32)\n",
        "        self.nxt = np.zeros((capacity, obs_dim), dtype=np.float32)\n",
        "        self.rew = np.zeros((capacity, 1), dtype=np.float32)\n",
        "        self.term = np.zeros((capacity, 1), dtype=np.float32)\n",
        "        self.ptr = 0; self.size = 0; self.cap = capacity\n",
        "\n",
        "    def add(self, s, a, r, sp, term):\n",
        "        \"\"\"Stroe one transition (s, a, r, s', done) into the replay buffer.\"\"\"\n",
        "        idx = self.ptr % self.cap\n",
        "        self.obs[idx] = s\n",
        "        self.act[idx] = a\n",
        "        self.nxt[idx] = sp\n",
        "        self.rew[idx] = r\n",
        "        self.term[idx] = term\n",
        "        self.ptr += 1\n",
        "        self.size = min(self.size +1, self.cap)\n",
        "\n",
        "    def sample(self, batch):\n",
        "        \"\"\"Return random batch \"\"\"\n",
        "        assert self.size > 0\n",
        "        idxs = np.random.randint(0, self.size, size=batch)\n",
        "        s = self.obs[idxs]\n",
        "        a = self.act[idxs]\n",
        "        sp = self.nxt[idxs]\n",
        "        delta_s = sp - s\n",
        "        return to_t(np.concatenate([s, a], axis = -1)), to_t(delta_s)\n",
        "\n",
        "replay = Replay(obs_dim, act_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "374692ef",
      "metadata": {
        "id": "374692ef"
      },
      "source": [
        "\n",
        "## Task 2. Collect Random Rollouts\n",
        "\n",
        "- Gather random actions for a number of steps to create our training dataset. Collect data for 100000 steps.\n",
        "- Call the function and fill the replay buffer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "e2d7b840",
      "metadata": {
        "id": "e2d7b840"
      },
      "outputs": [],
      "source": [
        "def collect_random(env, replay, steps=10000, seed=42, render=False):\n",
        "    \"\"\"Collect random experience tuples (s, a, r, s', done) and store in replay buff\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    obs, _ = env.reset(seed=seed)\n",
        "    total_steps = 0\n",
        "    ep_returns = []\n",
        "    ep_ret = 0\n",
        "\n",
        "    while total_steps < steps:\n",
        "      # sample random action uniformly from action space\n",
        "      a = np.random.uniform(env.action_space.low, env.action_space.high)\n",
        "\n",
        "      # step environment\n",
        "      next_obs, r, done, trunc, info = env.step(a)\n",
        "\n",
        "      # store in replay buffer\n",
        "      replay.add(obs, a, r, next_obs, float(done or trunc))\n",
        "\n",
        "      ep_ret += r\n",
        "      total_steps += 1\n",
        "      obs = next_obs\n",
        "\n",
        "      # handle episode termination\n",
        "      if done or trunc:\n",
        "        obs, _ = env.reset()\n",
        "        ep_returns.append(ep_ret)\n",
        "        ep_ret = 0\n",
        "\n",
        "      # optional rendeirng for debug\n",
        "      if render and total_steps % 2000 == 0:\n",
        "        env.render()\n",
        "\n",
        "    print(f\" Collected {replay.size} transitions over {len(ep_returns)} epsisodes.\")\n",
        "    print(f\" Average episodic return (random policy): {np.mean(ep_returns):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "env = gym.make(\"HalfCheetah-v4\")\n",
        "obs_dim = env.observation_space.shape[0]\n",
        "act_dim = env.action_space.shape[0]\n",
        "\n",
        "replay = Replay(obs_dim, act_dim)\n",
        "\n",
        "# Collect random data\n",
        "collect_random(env, replay, steps=100000)\n",
        "\n",
        "# Check buffer contents\n",
        "print(\"Replay buffer size:\", replay.size)\n",
        "x, y = replay.sample(5)\n",
        "print(\"Sample x shape:\", x.shape, \"y shape:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W961CV-6rFbS",
        "outputId": "2be11aa1-be1f-4a2b-a1f5-c1dce2898515"
      },
      "id": "W961CV-6rFbS",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Collected 100000 transitions over 100 epsisodes.\n",
            " Average episodic return (random policy): -291.06\n",
            "Replay buffer size: 100000\n",
            "Sample x shape: torch.Size([5, 23]) y shape: torch.Size([5, 17])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7689c7f",
      "metadata": {
        "id": "c7689c7f"
      },
      "source": [
        "\n",
        "## Task 3. Update normalizers from the collected random data in the replay buffer\n",
        "\n",
        "We normalize inputs (`[s,a]`) and targets (`Î”s = s' - s`) for stable training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "39332ea3",
      "metadata": {
        "id": "39332ea3",
        "outputId": "02f15f05-0e77-4605-be36-6dc5fc544dae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalizers ready.\n"
          ]
        }
      ],
      "source": [
        "obs_norm = RunningNormalizer(obs_dim)\n",
        "inp_norm = RunningNormalizer(obs_dim + act_dim)\n",
        "targ_norm = RunningNormalizer(obs_dim)\n",
        "\n",
        "# write the function to update the normalizers from the data collected in the buffer\n",
        "def update_normalizers_from_buffer(replay):\n",
        "    pass\n",
        "\n",
        "update_normalizers_from_buffer(replay)\n",
        "print(\"Normalizers ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "566164a4",
      "metadata": {
        "id": "566164a4"
      },
      "source": [
        "\n",
        "## Defining the Neural Dynamics Model\n",
        "\n",
        "We predict **normalized** `Î”s` from **normalized** `[s, a]`.\n",
        "NN parameters:\n",
        "\n",
        "- initialize a deterministic NN with a ExponentialLR sceduler( that decays the learning rate with epoch)\n",
        "- width = 200, depth = 3, lr = 1e-3, weight_decay - 1e-5, gamma for scheduler = 0.8\n",
        "- These are a starting point but not the best parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6d3eda1",
      "metadata": {
        "id": "a6d3eda1"
      },
      "outputs": [],
      "source": [
        "class DetMLP(nn.Module):\n",
        "    \"\"\"Predicts Î”state deterministically.\"\"\"\n",
        "    def __init__(self, in_dim, out_dim, width=200, depth=3):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        last = in_dim\n",
        "        for _ in range(depth):\n",
        "            layers += [nn.Linear(last, width), nn.ReLU()]\n",
        "            last = width\n",
        "        layers += [nn.Linear(last, out_dim)]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "        self.apply(fanin_init)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "in_dim = obs_dim + act_dim\n",
        "out_dim = obs_dim\n",
        "model = DetMLP(in_dim, out_dim, width=200, depth=3)\n",
        "opt = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(opt, gamma=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5a3db88",
      "metadata": {
        "id": "a5a3db88"
      },
      "source": [
        "\n",
        "## Task 4. Train the Model\n",
        "\n",
        "We minimize MSE between predicted normalized `Î”s` and target normalized `Î”s`.\n",
        "\n",
        "- Train in batches, keep the batch size 256\n",
        "- Use a learning rate scheduler that decays the learning rate as training progresses. You may use the pytorch utility. See how the learning rate decays with each epoch.\n",
        "- Train for 30 epochs and plot the training curve. Loss vs epoch.\n",
        "- Find the best parameters(defined in the previous block)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a39c80c",
      "metadata": {
        "id": "4a39c80c"
      },
      "outputs": [],
      "source": [
        "def train_model(model, replay, epochs=30, batch_size=256):\n",
        "    pass\n",
        "    # return losses\n",
        "\n",
        "# losses = train_model(model, replay, epochs=10, batch_size=64)\n",
        "# plt.figure()\n",
        "# plt.plot(losses)\n",
        "# plt.xlabel(\"Epoch\")\n",
        "# plt.ylabel(\"MSE (normalized Î”s)\")\n",
        "# plt.title(\"Model Training Loss\")\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34a1c7c0",
      "metadata": {
        "id": "34a1c7c0"
      },
      "source": [
        "## Task 5. Validate your model: One-Step and Multi-Step Prediction Error\n",
        "\n",
        "- Evaluate your trained model on a held-out set of random transitions.\n",
        "Generate a batch of unseen samples, predict the next-state delta, and compute the one-step MSE.\n",
        "\n",
        "- Repeat with open-loop rollouts of length k.\n",
        "Drive both the real environment and the model with the same action sequence, then report how prediction error grows across steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1efe4271",
      "metadata": {
        "id": "1efe4271"
      },
      "outputs": [],
      "source": [
        "\n",
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c5a173d",
      "metadata": {
        "id": "5c5a173d"
      },
      "source": [
        "\n",
        "## Task 6. Visualize Rollout Trajectories\n",
        "\n",
        "**Setup**\n",
        "Call model.eval() so gradients stay off.\n",
        "Reset the env with the provided seed; keep a copy of the initial observation.\n",
        "\n",
        "\n",
        "**Choose actions**\n",
        "Pre-sample k actions from env.action_space.sample() so the real system and the model rollout see the same sequence.\n",
        "\n",
        "**Roll forward**\n",
        "For each action:\n",
        "Step the real env (env.step(a)), append the new observation.\n",
        "For the model path:\n",
        "Build [s_model, a], normalize via inp_norm.normalize, turn into a tensor with to_t.\n",
        "Run the network, de-normalize with targ_norm.denormalize, add to the last model state, append.\n",
        "Stop early if the env terminates or truncates.\n",
        "\n",
        "**Plot**\n",
        "Plot the real trajectory as one line, model trajectory as another.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aebb7a76",
      "metadata": {
        "id": "aebb7a76"
      },
      "outputs": [],
      "source": [
        "\n",
        "def visualize_rollout(env, model, k=50, dims=(0, 5, 10), seed=2025):\n",
        "    pass\n",
        "\n",
        "# Uncomment to visualize\n",
        "dims = list(range(1, 17))\n",
        "# visualize_rollout(env, model, k=50, dims=dims)#(qvel_start, qvel_start+1, qvel_start+2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c34f48f2",
      "metadata": {
        "id": "c34f48f2"
      },
      "source": [
        "\n",
        "## 9. Answer the questions :\n",
        "\n",
        "1. How good is your model?\n",
        "2. Is this training enough for planning, or do we need continual training?\n",
        "3. How is this system different from the mountain car problem? Why can't we learn this in one episode?\n",
        "4. Why do we use a runningnormalizer instead of a static normalizer? Think about the nature of the algorithm taught in class.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mquad_cuda",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}